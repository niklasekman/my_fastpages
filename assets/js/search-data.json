{
  
    
        "post0": {
            "title": "Engine knock detection AI part 5/5",
            "content": "Summary . Almost a year and a half ago I trained a model using the fastai library to identify knocking in a car engine. . The initial success had me really excited. This could be a really cool thing to continue working on. One could measure vibrations and sounds using contact microphones like pizeos to get better data and to train th model further. I found otosense, now aquired by Analog Devices, and 3d signals. Two companies which seem to do something along those lines. . The project was put on a back burner when the fall semester of 2019 kicked into full gear and kept there while studying from home during 2020. . The training notebook I&#39;ve posted previously does not really run from start to finish anymore since the fastai library has been updated. I decided to train a new model with the same dataset but using fastai v2 this time. . Now I&#39;ve done more experimenting with different networks, but came to the conclusion that resnet34 as used originally seems like a good fit for now. Retraining the model with fastai v2 yields similar results as earlier. . To bring the project status to something resembling completion I&#39;ve also deployed the trained model as a Telegram bot, ismyengineknocking_bot. Send the bot a short video of an engine running and it will try to determine if it&#39;s running normally or knocking. . Setup . Install the fastai library and initialize the notebook. This differs from how it was made in v1. . !pip install -Uqq fastbook import fastbook fastbook.setup_book() . |████████████████████████████████| 727kB 7.6MB/s |████████████████████████████████| 51kB 8.0MB/s |████████████████████████████████| 1.2MB 16.3MB/s |████████████████████████████████| 194kB 35.6MB/s |████████████████████████████████| 61kB 8.4MB/s Mounted at /content/gdrive . I left this piece in even if it&#39;s not really needed since the initialization in the last cell already mounts Drive. This just lets me copy and paste the paths from the earlier notebooks without change. . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . The obligatory importing of modules. . from fastbook import * from fastai.vision.all import * . Since typing this everytime gets old quickly. . path = Path(&#39;/content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data&#39;) . Load the training data . This differs slightly from earlier. The new syntax is a lot cleaner. . 20% of the images is used for the validation set. These are images set aside from the data the model is trained on and are used to see how the model fares when presented with images not encountered previously. . dataset = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, batch_tfms=Normalize(), item_tfms=Resize(224)) . Display images from dataset . This notebook does not delve into the depths of creating the dataset. Two notebooks have been published previously on the topic. But as a summary it can be said that the soundtracks from car maintenance videos on youtube were sliced up into two second clips. The images seen below are spectrograms of those clips showing the sound intensity at different frequencies as a function of time. . Vertical bars or lines in the images represent rythmic content in the audio. As the audio recorded is of internal combustion engines there is a background, or normal, rythmic sound. The model is expected to learn how different the sound &quot;looks&quot; when the engine is knocking. The condition occurs when ignition of the air/fuel mixture in one or more cylinders does not occur as it should. This can sound slightly different depending on the engine and the resulting spectrogram can look very different. . The top right image shows a high intensity noise in the middle of the frequency range which is typical for the knocking engines in the dataset. The mid right shows wide spikes of a sound with distinct wavy horizontal lines. These represent the harmonic series of a human voice. In other words, I left in clips where the author of the video talks about the problems, or lack thereof. There are clips with narration in both the normal and knocking categories. . dls = dataset.dataloaders(path) dls.valid.show_batch(max_n=9, nrows=3) . Train the model . The method from the previous training notebook is tested first. Syntax has changed slightly since fastai v1. The model is first trained for four epochs, the top layers unfrozen and then the learning rate finder is used to show the loss as a funtion of the step size, sometimes called alpha or learning rate like here. . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fit_one_cycle(4) learn.unfreeze() . Downloading: &#34;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth . . epoch train_loss valid_loss error_rate time . 0 | 1.128035 | 0.887554 | 0.459770 | 01:23 | . 1 | 0.930411 | 1.058884 | 0.482759 | 00:03 | . 2 | 0.761746 | 1.076087 | 0.425287 | 00:02 | . 3 | 0.652740 | 0.877649 | 0.344828 | 00:02 | . SuggestedLRs(lr_min=0.0001737800776027143, lr_steep=7.585775847473997e-07) . learn.lr_find() . The error rate and validation loss does not go down as far as during the previous training. . Validation loss is a metric which tells how well the model performs when it tries to categorize images in the validation set after training for a cycle. . The validation loss was about 10% smaller in the old notebook. . learn.fit_one_cycle(2, lr_max=slice(4e-6,4e-4)) . epoch train_loss valid_loss error_rate time . 0 | 0.320230 | 0.640691 | 0.229885 | 00:03 | . 1 | 0.249299 | 0.581090 | 0.195402 | 00:03 | . learn.recorder.plot_loss() . The model seems to consistently guess that an engine is knocking while it actually is running well more often than the reverse. This was the case in the first notebook as well. It could be argued that this is a better scenario since this makes one err on the side of caution. The numbers are slightly worse than last time though. . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Trying out resnet18 for a few epochs. The validation loss does not really impress at 0.75. . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(6) learn.recorder.plot_loss() interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Downloading: &#34;https://download.pytorch.org/models/resnet18-5c106cde.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth . . epoch train_loss valid_loss error_rate time . 0 | 1.166217 | 1.155197 | 0.540230 | 00:02 | . epoch train_loss valid_loss error_rate time . 0 | 0.825857 | 1.285291 | 0.505747 | 00:02 | . 1 | 0.620117 | 0.998950 | 0.448276 | 00:02 | . 2 | 0.449343 | 0.805288 | 0.356322 | 00:02 | . 3 | 0.350883 | 0.796160 | 0.252874 | 00:02 | . 4 | 0.279821 | 0.772651 | 0.252874 | 00:02 | . 5 | 0.230751 | 0.750805 | 0.252874 | 00:02 | . Resnet50 is even worse with a validation loss which just keeps climbing with training. . learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16() learn.fine_tune(6, freeze_epochs=3) learn.recorder.plot_loss() interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Downloading: &#34;https://download.pytorch.org/models/resnet50-19c8e357.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth . . epoch train_loss valid_loss error_rate time . 0 | 1.172437 | 1.199191 | 0.528736 | 00:02 | . 1 | 0.986341 | 0.814950 | 0.379310 | 00:02 | . 2 | 0.749940 | 0.999910 | 0.356322 | 00:02 | . epoch train_loss valid_loss error_rate time . 0 | 0.218681 | 0.925836 | 0.344828 | 00:03 | . 1 | 0.221640 | 1.123302 | 0.310345 | 00:03 | . 2 | 0.251672 | 1.212892 | 0.344828 | 00:03 | . 3 | 0.221463 | 1.254364 | 0.310345 | 00:03 | . 4 | 0.175679 | 1.195390 | 0.275862 | 00:03 | . 5 | 0.145948 | 1.179999 | 0.275862 | 00:03 | . Resnet34 gave the best results so far. In the following fine_tune gives similar results as running manually. . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(2, freeze_epochs=4) learn.recorder.plot_loss() interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . epoch train_loss valid_loss error_rate time . 0 | 1.355901 | 1.024774 | 0.609195 | 00:03 | . 1 | 1.209846 | 1.169116 | 0.505747 | 00:03 | . 2 | 1.032370 | 1.075739 | 0.402299 | 00:02 | . 3 | 0.853908 | 0.984360 | 0.333333 | 00:02 | . epoch train_loss valid_loss error_rate time . 0 | 0.358774 | 0.707381 | 0.241379 | 00:03 | . 1 | 0.284909 | 0.626451 | 0.264368 | 00:03 | . The validation loss seems to be going down still. An increase of epochs after the freeze should be possible. The performance is till on par with the manual method. Metrics are not too far away from the first notebook. . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(6, freeze_epochs=4) learn.recorder.plot_loss() interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . epoch train_loss valid_loss error_rate time . 0 | 1.374766 | 1.093510 | 0.643678 | 00:03 | . 1 | 1.197061 | 1.271672 | 0.471264 | 00:02 | . 2 | 0.976585 | 1.134578 | 0.379310 | 00:02 | . 3 | 0.819463 | 0.856113 | 0.298851 | 00:02 | . epoch train_loss valid_loss error_rate time . 0 | 0.320615 | 0.587391 | 0.229885 | 00:03 | . 1 | 0.234541 | 0.593262 | 0.241379 | 00:03 | . 2 | 0.201834 | 0.613296 | 0.252874 | 00:03 | . 3 | 0.162961 | 0.466194 | 0.195402 | 00:03 | . 4 | 0.130873 | 0.430470 | 0.149425 | 00:03 | . 5 | 0.108552 | 0.419990 | 0.183908 | 00:03 | . Plot top losses . It seems like the model is guessing that spectrograms with vertical lines correspond to knocking, which would be correct. The bottom mid file has some narration which apparently threw the model off. . interp.plot_top_losses(9, nrows=3) . Possible future exploration should involve trying to gather a bigger dataset. Also trying out the fastaudio package would be interesting. . Preparations for deployment . Checking package versions . Ideally the same versions of packages, libraries and tools should be used on the server which the model is deployed on. The versions used can be checked with the following. . !python --version . Python 3.6.9 . import fastai fastai.__version__ . &#39;2.2.5&#39; . torch.__version__ . &#39;1.7.0+cu101&#39; . import torchvision torchvision.__version__ . &#39;0.8.1+cu101&#39; . Exporting the model . The model needs to be exported and copied over to a Drive folder so that it is retained when the Colab instance shuts down. . learn.export(&quot;model_v2.pkl&quot;) . Copying the model to Google Drive for posteriority. . !cp /content/model_v2.pkl /content/drive/MyDrive/Colab Notebooks/fast.ai/data/model_v2.pkl . Testing the model . Load the model if starting from here. . !cp /content/drive/MyDrive/Colab Notebooks/fast.ai/data/model_v2.pkl /content/model_v2.pkl . learn = load_learner(&quot;model_v2.pkl&quot;) . Load the outboard engine video, slice out the middle 2 seconds, create a spectrogram and let the model predict the state. . . project_path = &#39;/content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock&#39; mov_filename = &#39;IMG_3414.MOV&#39; import moviepy.editor as mp clip = mp.VideoFileClip(project_path + &#39;/&#39; + mov_filename) . clip_start = (clip.duration/2)-1 clip_end = (clip.duration/2)+1 . clip = clip.subclip(clip_start,clip_end) . sr = clip.audio.fps y = clip.audio.to_soundarray() y = y[...,0:1:1].flatten() # Take one channel, transform rows to columns, 1D . import librosa import matplotlib.pyplot as plt import librosa.display from PIL import ImageMath from fastai.data.external import * D = librosa.stft(y) D_harmonic, D_percussive = librosa.decompose.hpss(D) # Pre-compute a global reference power from the input spectrum rp = np.max(np.abs(D)) side_px=256 dpi=150 plot = plt.figure(figsize=(side_px/dpi, side_px/dpi)) CQT = librosa.amplitude_to_db(np.abs(librosa.cqt(librosa.istft(D_percussive), sr=sr)), ref=np.max) p=librosa.display.specshow(CQT,x_axis=None,y_axis=None) plt.axis(&#39;off&#39;) plot.canvas.draw() # https://stackoverflow.com/questions/7821518/matplotlib-save-plot-to-numpy-array im_data = np.fromstring(plot.canvas.tostring_rgb(), dtype=np.uint8, sep=&#39;&#39;) im_data = im_data.reshape(plot.canvas.get_width_height()[::-1] + (3,)) pred_class,pred_idx,outputs = learn.predict(im_data) pred_class . &#39;knocking&#39; . outputs[pred_idx] . tensor(1.0000) . The video is a bit of a stress test since the sound is from a single cylinder 4-stroke engine. A car engine has several cylinders which makes the sound &quot;smoother&quot; in comparison. . The following is a test of classifying a warmed up healthy Volvo V70 engine. . . import moviepy.editor as mp import librosa import matplotlib.pyplot as plt import librosa.display from PIL import ImageMath from fastai.data.external import * mov_filename = &#39;IMG_E5373.MOV&#39; project_path = &#39;/content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock&#39; clip = mp.VideoFileClip(project_path + &#39;/&#39; + mov_filename) clip_start = (clip.duration/2)-1 clip_end = (clip.duration/2)+1 clip = clip.subclip(clip_start,clip_end) sr = clip.audio.fps y = clip.audio.to_soundarray() y = y[...,0:1:1].flatten() D = librosa.stft(y) D_harmonic, D_percussive = librosa.decompose.hpss(D) rp = np.max(np.abs(D)) side_px=256 dpi=150 plot = plt.figure(figsize=(side_px/dpi, side_px/dpi)) CQT = librosa.amplitude_to_db(np.abs(librosa.cqt(librosa.istft(D_percussive), sr=sr)), ref=np.max) p=librosa.display.specshow(CQT,x_axis=None,y_axis=None) plt.axis(&#39;off&#39;) plot.canvas.draw() im_data = np.fromstring(plot.canvas.tostring_rgb(), dtype=np.uint8, sep=&#39;&#39;) im_data = im_data.reshape(plot.canvas.get_width_height()[::-1] + (3,)) pred_class,pred_idx,outputs = learn.predict(im_data) pred_class . &#39;normal&#39; . outputs[pred_idx] . tensor(1.0000) . The above can only be read as that model is as confident as it can be about the engine running normally. . Deployment as a telegram bot . Following the example from Kevin Degila&#39;s Medium post How to deploy Machine Learning models on Android and IOS with Telegram Bots it&#39;s possible to make the model relatively easily accessible for testing. The user can record a short video clip of their car running and send it to the bot for analysis. There&#39;s no need to build an app for mobile or even a web app where one would have to deal with clunky uploading UIs in mobile browsers. The user only needs the free chat app. . Create the bot . Open the Telegram app and start a conversation with @BotFather. Give the /newbot command and answer the questions. An API key is given at the end of the conversation which needs to be used in the python file which defines the behaviour of the new bot. . . To start development on the local machine I&#39;m using Anaconda to manage python environments, which means that I can have several different setups of python versions and associated modules installed for different projects. . With the tool installed the following can be entered in the Anaconda Prompt to create a new environment for this project with the same python version as this notebook was created on. . conda create --name knock python=3.6.9 . and . conda activate knock . to change to the new environment. . Fastai can be installed with . conda install -c fastai -c pytorch fastai=2.2.5 . The module needed for connecting to the Telegram API is installed with . pip install python-telegram-bot . The moviepy module is used to load and slice the video file, librosa for creating spectrograms . pip install moviepy librosa . The entire functionality of the bot is defined in a file called main.py. The whole file, except the API key, is presented below. . import logging from telegram.ext import Updater, CommandHandler, MessageHandler, Filters from fastai.vision.all import load_learner import numpy as np import moviepy.editor as mp import librosa import matplotlib.pyplot as plt import librosa.display from PIL import ImageMath from fastai.data.external import * # UNCOMMENT the following if running the bot LOCALLY ON WINDOWS #import pathlib #temp = pathlib.PosixPath #pathlib.PosixPath = pathlib.WindowsPath def start(update, context): update.message.reply_text( &quot;Bot by @niklasekman on Twitter n n&quot; &quot;Just send me a short (min 2s) video of your car engine running with the hood up and I&#39;ll try to tell you if it is running normally or possibly knocking. nI will only look at 2 seconds in the middle of the video. nYour video will not be saved. An example of what I&#39;m expecting can be seen here https://youtu.be/qBAbQakgK60&quot; ) def help_command(update, context): update.message.reply_text(&#39;I will tell you if your car engine is running normally or knocking. Send a short video.&#39;) def load_model(): global model model = load_learner(&#39;model_v2.pkl&#39;) print(&#39;Model loaded&#39;) def create_spectrogram(filename): clip = mp.VideoFileClip(filename) clip_start = (clip.duration/2)-1 clip_end = (clip.duration/2)+1 clip = clip.subclip(clip_start,clip_end) sr = clip.audio.fps y = clip.audio.to_soundarray() y = y[...,0:1:1].flatten() D = librosa.stft(y) D_harmonic, D_percussive = librosa.decompose.hpss(D) rp = np.max(np.abs(D)) side_px=256 dpi=150 plot = plt.figure(figsize=(side_px/dpi, side_px/dpi)) CQT = librosa.amplitude_to_db(np.abs(librosa.cqt(librosa.istft(D_percussive), sr=sr)), ref=np.max) p=librosa.display.specshow(CQT,x_axis=None,y_axis=None) plt.axis(&#39;off&#39;) plot.canvas.draw() im_data = np.fromstring(plot.canvas.tostring_rgb(), dtype=np.uint8, sep=&#39;&#39;) im_data = im_data.reshape(plot.canvas.get_width_height()[::-1] + (3,)) return im_data def infer_knocking(update, context): user = update.message.from_user video_file = update.message.video.get_file() video_file.download(&#39;user_video.mp4&#39;) label = model.predict(create_spectrogram(&#39;user_video.mp4&#39;))[0] if label == &quot;normal&quot;: update.message.reply_text(&quot;Your engine seems to be running well. If you are suspecting problems with your car, please contact a mechanic. I&#39;m just a stupid bot and I&#39;m giving my opinion after seeing literally 15 videos on youtube.&quot;) else: update.message.reply_text(&quot;Your engine could be knocking. If you are suspecting problems with your car, please contact a mechanic. I&#39;m just a stupid bot and I&#39;m giving my opinion after seeing literally 15 videos on youtube.&quot;) def main(): load_model() updater = Updater(token=&quot;************* API key **********&quot;, use_context=True) dp = updater.dispatcher dp.add_handler(CommandHandler(&quot;start&quot;, start)) dp.add_handler(CommandHandler(&quot;help&quot;, help_command)) dp.add_handler(MessageHandler(Filters.video, infer_knocking)) updater.start_polling() updater.idle() if __name__ == &#39;__main__&#39;: main() . With the code from above in main.py in a suitable project directory run . python main.py . and start a chat with the bot. Mine is called ismyengineknocking_bot if you just want to try it out. Send a short video to it and get a guesstimation about the status of your engine. . Deploy the bot to Heroku . The previous is what is needed to run the bot locally. For running continuously on a server one should use webhooks instead of polling. Referring to the line updater.start_polling() line near the end of the main.py file. Deploying on Heroku, as I&#39;ve done, requires the project to be put under version contol with Git. . There are some more traps for young players which I&#39;ve tried to summarize in the list under the next heading in bullet form. There are a lot of guides that can be found by googling fastai telegram bot but they mostly just take an image the user sends and feed it to the fastai predict function. Things can get a bit hairy if something more has to be done to process the data from the user. . Heroku is a hosting platform with a free tier for hobby and non-commercial projects. . The following steps need to be taken in order to get the bot running on the platform . Create an account on Heroku | Go through the Getting started guide in the documentation | Install the Git version control system | Install the Heroku command line interface | Rewrite the python script to use webhooks instead of polling | Create a new app in the Heroku dashboard | Put the project under vesion control and push it to Heroku as per the instuctions on the Deploy tab in the dashboard | Turn the dyno on under the Resources tab | . As with any web development project the bot script will have dependencies, i.e. pieces of software written by other people that it relies on. Gathering all of them and making them work in the production environment can be a hassle. The following list contains both general advice and some specific things to note regarding this particular project. . Check the Heroku Python Support page to see which Python versions are available on different dynos. Test the script locally in a new anaconda environment first if it&#39;s necessary to up- or downgrade the version of Python. | Put the version of Python, e.g. python-3.6.12 in a file called runtime.txt | See which modules the script is likely to need by issuing pip freeze or pip list --format=freeze to see what&#39;s installed in the environment | Copy in the names of the most important modules along with the versions used into requirements.txt in the project directory. Mine looks like | . python-telegram-bot==13.2 -f https://download.pytorch.org/whl/torch_stable.html fastai==2.2.5 torch==1.7.1+cpu torchvision==0.8.2+cpu librosa==0.8.0 moviepy==1.0.3 SoundFile==0.10.3.post1 . The installation of modules on the server may fail if all of the modules which are mentioned in the list from the earlier commands are copied into the requirements file. There might be incompatibilites that are difficult to predict that prevent installation of the exact versions of all modules. Specifying the ones that are absolutely necessary and letting pip resolve the rest of the modules is a better strategy | Use the cpu versions of the torch and torchvision so that the slug of your Heroku projects doesn&#39;t get too big (max is 500 MB) | The librosa, moviepy and SoundFile are specific to this project and are used to prepare videos. | There were some problems with installing the librosa module which were due to the fact that the Ubuntu based environment on Heroku does not have the libsndfile1 and libsndfile-dev installed by default. They can be installed during the build by putting their names in a file called Aptfile and adding the community apt buildpack heroku-community/apt to the project under the Settings tab. See also the heroku-buildpack-apt documentation. | .",
            "url": "https://niklasekman.com/2021/02/10/Train-model-updated.html",
            "relUrl": "/2021/02/10/Train-model-updated.html",
            "date": " • Feb 10, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Engine knock detection AI part 4/5",
            "content": "Method . Setup . !curl -s https://course.fast.ai/setup/colab | bash . Updating fastai... Done. . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True). . . from fastai.vision import * . path = Path(&#39;/content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data&#39;) . defaults.device = torch.device(&#39;cpu&#39;) . Loading the previously trained model . classes = [&#39;knocking&#39;,&#39;normal&#39;] . data = ImageDataBunch.single_from_classes(path, classes, size=224).normalize(imagenet_stats) learn = create_cnn(data,models.resnet34) learn.load(&#39;stage-2&#39;) . Learner(data=ImageDataBunch; Train: LabelList (0 items) x: ImageList y: CategoryList Path: /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data; Valid: LabelList (0 items) x: ImageList y: CategoryList Path: /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data; Test: None, model=Sequential( (0): Sequential( (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace) (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (4): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (5): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (6): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (4): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (5): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (7): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) ) (1): Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): Flatten() (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25) (4): Linear(in_features=1024, out_features=512, bias=True) (5): ReLU(inplace) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5) (8): Linear(in_features=512, out_features=2, bias=True) ) ), opt_func=functools.partial(&lt;class &#39;torch.optim.adam.Adam&#39;&gt;, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath(&#39;/content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data&#39;), model_dir=&#39;models&#39;, callback_fns=[functools.partial(&lt;class &#39;fastai.basic_train.Recorder&#39;&gt;, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential( (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace) (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (6): ReLU(inplace) (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (11): ReLU(inplace) (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (16): ReLU(inplace) (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (19): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (21): ReLU(inplace) (22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (23): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (24): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (28): ReLU(inplace) (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (31): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (32): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (33): ReLU(inplace) (34): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (35): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (36): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (38): ReLU(inplace) (39): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (40): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ), Sequential( (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace) (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (9): ReLU(inplace) (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (14): ReLU(inplace) (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (19): ReLU(inplace) (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (24): ReLU(inplace) (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (29): ReLU(inplace) (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (32): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (33): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (34): ReLU(inplace) (35): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (36): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (37): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (41): ReLU(inplace) (42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (44): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (46): ReLU(inplace) (47): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ), Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): AdaptiveMaxPool2d(output_size=1) (2): Flatten() (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (4): Dropout(p=0.25) (5): Linear(in_features=1024, out_features=512, bias=True) (6): ReLU(inplace) (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (8): Dropout(p=0.5) (9): Linear(in_features=512, out_features=2, bias=True) )], add_time=True, silent=False, cb_fns_registered=False) . . Using the model for prediciton . Loading a video file . !pip install moviepy . Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (0.2.3.5) Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.16.5) Requirement already satisfied: decorator&lt;5.0,&gt;=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.4.0) Requirement already satisfied: tqdm&lt;5.0,&gt;=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.28.1) Requirement already satisfied: imageio&lt;3.0,&gt;=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (2.4.1) Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio&lt;3.0,&gt;=2.1.2-&gt;moviepy) (4.3.0) Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow-&gt;imageio&lt;3.0,&gt;=2.1.2-&gt;moviepy) (0.46) . Extracting 2 seconds from the video file for analysis. . project_path = &#39;/content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock&#39; mov_filename = &#39;IMG_3414.MOV&#39; import moviepy.editor as mp clip = mp.VideoFileClip(project_path + &#39;/&#39; + mov_filename).subclip(4,6); clip . &lt;moviepy.video.io.VideoFileClip.VideoFileClip at 0x7f6b7acb6a58&gt; . clip.ipython_display(width=360) . Output hidden; open in https://colab.research.google.com to view. . . Generating a spectrogram . Preparing the audio track from the video for librosa. . sr = clip.audio.fps y = clip.audio.to_soundarray() y = y[...,0:1:1].flatten() # Take one channel, transform rows to columns, 1D . The following is the same process which was done when creating the training dataset. . import librosa . D = librosa.stft(y) . D_harmonic, D_percussive = librosa.decompose.hpss(D) . rp = np.max(np.abs(D)) . import matplotlib.pyplot as plt import librosa.display side_px=256 dpi=150 plot = plt.figure(figsize=(side_px/dpi, side_px/dpi)) CQT = librosa.amplitude_to_db(np.abs(librosa.cqt(librosa.istft(D_percussive), sr=sr)), ref=np.max) p=librosa.display.specshow(CQT,x_axis=None,y_axis=None) plt.axis(&#39;off&#39;) . (0.0, 173.0, 0.0, 84.0) . The image is actually a matplotlib figure. The predict function of the fastai learner expects to be given a tensor to work with. Could be that the conversion had been easier if the spectrogram was saved out to a file first and then loaded from disk. The idea is to deploy the model later on a web server and it&#39;s best to avoid unnecessary disk access for temporary files. . type(plot) . matplotlib.figure.Figure . A little googling turned up a short tutorial on turning a figure into a PIL RGBA image. The idea being that the PIL image could then be converted to a tensor. The original URL in the comment below is now broken but as luck would have it the wayback machine has a snapshot of it here. . !pip install Pillow . Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0) Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46) . def fig2data ( fig ): &quot;&quot;&quot; @brief Convert a Matplotlib figure to a 4D numpy array with RGBA channels and return it @param fig a matplotlib figure @return a numpy 3D array of RGBA values &quot;&quot;&quot; # draw the renderer fig.canvas.draw ( ) # Get the RGBA buffer from the figure w,h = fig.canvas.get_width_height() buf = np.fromstring ( fig.canvas.tostring_argb(), dtype=np.uint8 ) buf.shape = ( w, h,4 ) # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have it in RGBA mode buf = np.roll ( buf, 3, axis = 2 ) return buf . from PIL import Image as pil_Image # http://www.icare.univ-lille1.fr/tutorials/convert_a_matplotlib_figure def fig2img ( fig ): &quot;&quot;&quot; @brief Convert a Matplotlib figure to a PIL Image in RGBA format and return it @param fig a matplotlib figure @return a Python Imaging Library ( PIL ) image &quot;&quot;&quot; # put the figure pixmap into a numpy array buf = fig2data ( fig ) w, h, d = buf.shape return pil_Image.frombytes( &quot;RGBA&quot;, ( w ,h ), buf.tostring( ) ) . Converting the figure to an image . im = fig2img(plot) . im . and turning the image into a tensor. . from PIL import ImageMath im_float = ImageMath.eval(&quot;convert(a,&#39;F&#39;)&quot;, a=im) im_tensor = pil2tensor(im_float, np.float32) . im_fastai = Image(px=im_tensor) . Predicting the state of the engine . Finally the tensor can be given to fastai. The model seems to think that the engine runs normally. . pred_class,pred_idx,outputs = learn.predict(im_fastai) pred_class . Category normal .",
            "url": "https://niklasekman.com/2019/09/16/Test_model_commented.html",
            "relUrl": "/2019/09/16/Test_model_commented.html",
            "date": " • Sep 16, 2019"
        }
        
    
  
    
        ,"post2": {
            "title": "Engine knock detection AI part 3/5",
            "content": "Background . With the training dataset created the model can be trained. This is copying almost verbatim from the second lesson in Practical Deep Learning for Coders, found at the github repo for the third installment of the course. The steps are described quite well in the linked notebook. . Method . Update fast.ai library . !curl -s https://course.fast.ai/setup/colab | bash . Updating fastai... Done. . Connect to google drive . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&amp;response_type=code Enter your authorization code: ·········· Mounted at /content/drive . . Import fast.ai . from fastai.vision import * . Define classes . classes = [&#39;knocking&#39;,&#39;normal&#39;] . Set path to working directory . path = Path(&#39;/content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data&#39;) . Validate image files . for c in classes: print(c) verify_images(path/c) . Define data object . np.random.seed(42) data = ImageDataBunch.from_folder(path, train=&quot;.&quot;, valid_pct=0.2, size=224, num_workers=4).normalize(imagenet_stats) . Verify data classes . data.classes . [&#39;knocking&#39;, &#39;normal&#39;] . Display images from dataset . As demonstrated by these images the knocking displays as vertical spikes in the middle of the spectrum. Some spectrograms for non knocking engines show rythmic components in the lower frequencies (top row middle). It will be interesting how well the model will be able to distinguish from these. . data.show_batch(rows=3, figsize=(7,8)) . Show image classes and counts . data.classes, data.c, len(data.train_ds), len(data.valid_ds) . ([&#39;knocking&#39;, &#39;normal&#39;], 2, 349, 87) . Fetch resnet34 model . learn = cnn_learner(data, models.resnet34, metrics=error_rate) . Downloading: &#34;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#34; to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth 100%|██████████| 87306240/87306240 [00:00&lt;00:00, 114748481.59it/s] . Train model . learn.fit_one_cycle(4) . epoch train_loss valid_loss error_rate time . 0 | 0.812924 | 0.703951 | 0.425287 | 00:07 | . 1 | 0.695543 | 0.604884 | 0.321839 | 00:04 | . 2 | 0.568838 | 0.543995 | 0.241379 | 00:04 | . 3 | 0.474682 | 0.468180 | 0.229885 | 00:04 | . Save model . learn.save(&#39;stage-1&#39;) . Unfreeze top layers . learn.unfreeze() . Find learning rate . learn.lr_find() . LR Finder is complete, type {learner_name}.recorder.plot() to see the graph. . Plot learning rate . # learn.lr_find(start_lr=1e-5, end_lr=1e-1) learn.recorder.plot() . Retrain top layers . learn.fit_one_cycle(2, max_lr=slice(4e-6,4e-4)) . epoch train_loss valid_loss error_rate time . 0 | 0.018658 | 0.468953 | 0.195402 | 00:05 | . 1 | 0.013044 | 0.466273 | 0.172414 | 00:05 | . Save model . learn.save(&#39;stage-2&#39;) . Interpret model . Load model . learn.load(&#39;stage-2&#39;); . Create interpreation from learner . interp = ClassificationInterpretation.from_learner(learn) . Plot confusion matrix . The confusion matrix shows that the model is quite confident in predicting wether the engine is knocking or not. Only once did it think that an engine ran normally when it was in fact knocking. This case could be seen as the more harmful on. . interp.plot_confusion_matrix() . Plot top losses . Looking at the cases where the model was the most unsure also gives the impression that it&#39;s quite good. The top row would be hard for me to classify correctly based on the spectrograms. Looking closely at the third one (top right) you can suspect somehing is going on with the vertical lines in the top middle of the image. . losses,idxs = interp.top_losses(10) len(data.valid_ds)==len(losses)==len(idxs) interp.plot_top_losses(9) . Show audiofile players for top losses . Listening to the audio for the previously mentioned third spectrogram (knocking/0042_1.wav below) it&#39;s pretty clear that the engine isn&#39;t running well. . import IPython.display as ipd import os . for img_path in data.valid_ds.items[idxs]: filepath, extension = os.path.splitext(img_path) audio_slice_path = filepath + &#39;.wav&#39; print(filepath) ipd.display(ipd.Audio(audio_slice_path)) . /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/normal/0046_4 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/normal/0044_3 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/knocking/0042_1 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/normal/0012_4 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/knocking/0002_1 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/normal/0042_2 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/knocking/0016_2 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/knocking/0002_0 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/knocking/0035_1 . Your browser does not support the audio element. /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/normal/0032_2 . Your browser does not support the audio element. Export model . learn.export() .",
            "url": "https://niklasekman.com/2019/09/15/Train_model_commented.html",
            "relUrl": "/2019/09/15/Train_model_commented.html",
            "date": " • Sep 15, 2019"
        }
        
    
  
    
        ,"post3": {
            "title": "Engine knock detection AI part 2/5",
            "content": "Setup . Basics . Since this ran on Google Colab and the audio files are in a Drive folder, Google Drive is first mounted. . from google.colab import drive drive.mount(&#39;/content/gdrive&#39;, force_remount=True) root_dir = &quot;/content/gdrive/My Drive/&quot; base_dir = root_dir + &#39;Colab Notebooks/fast.ai/KnockKnock/data/&#39; # /content/gdrive/My Drive/Colab Notebooks/fast.ai/data/ . Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&amp;response_type=code Enter your authorization code: ·········· Mounted at /content/gdrive . . Importing the needed modules. Librosa is used for spectral decomposition. . from __future__ import print_function import numpy as np import matplotlib.pyplot as plt import librosa import librosa.display import IPython.display as ipd . Selecting an audiofile to experiment on. . audiofile_path = base_dir+&#39;knocking/0005.wav&#39; . Loading the audiofile . Load two seconds of audio from the specified file. The load function returns both the data, y, and information on the sample rate, sr. . y, sr = librosa.load(audiofile_path, duration=2, offset=0) . Pre-processing audio . Calculate the Short-time Fourier transform using the stft function and perform Median-filtering harmonic percussive source separation with the decompose.hpss function. . Sounds real fancy but the gist of it is that the latter function attempts to split the audio into harmonic and percussive elements. As the sound one is listening for when determining if an engine is knocking is more of a percussive or transient kind, this will make it easier to train the classifier model. . D = librosa.stft(y) D_harmonic, D_percussive = librosa.decompose.hpss(D) . Examining results . Plot the spectrograms of the original, harmonic and percussive content. Even though the knocking is visible in the full spectrogram it is a lot clearer in the percussive one. . # Pre-compute a global reference power from the input spectrum rp = np.max(np.abs(D)) plt.figure(figsize=(12, 8)) plt.subplot(3, 1, 1) librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp), y_axis=&#39;log&#39;) plt.colorbar() plt.title(&#39;Full spectrogram&#39;) plt.subplot(3, 1, 2) librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic), ref=rp), y_axis=&#39;log&#39;) plt.colorbar() plt.title(&#39;Harmonic spectrogram&#39;) plt.subplot(3, 1, 3) librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp), y_axis=&#39;log&#39;, x_axis=&#39;time&#39;) plt.colorbar() plt.title(&#39;Percussive spectrogram&#39;) plt.tight_layout() . . It is possible to run an inverse fourier tranform on the harmonic and percussive content in order to hear the difference. . First up is the original sound. . ipd.Audio(y,rate=sr) . Your browser does not support the audio element. Next is the harmonic content. . ipd.Audio(librosa.istft(D_harmonic),rate=sr) . Your browser does not support the audio element. And lastly the percussive. The knocking is quite pronounced. . ipd.Audio(librosa.istft(D_percussive),rate=sr) . Your browser does not support the audio element. Preparing plots for output . The images used to train a classifier should ideally be square and relatively small. The following documents the steps necessary to get a borderless square plot of a spectrogram. . mydpi=150 pix_side=256 . Here is the original sound file for comparison. . plt.figure(figsize=(pix_side/mydpi, pix_side/mydpi)) CQT = librosa.amplitude_to_db(np.abs(librosa.cqt(y, sr=sr)), ref=np.max) librosa.display.specshow(CQT,x_axis=None,y_axis=None) plt.axis(&#39;off&#39;) . (0.0, 87.0, 0.0, 84.0) . And this is the spectrogram of the percussive content in the same format. . plt.figure(figsize=(pix_side/mydpi, pix_side/mydpi)) CQT = librosa.amplitude_to_db(np.abs(librosa.cqt(librosa.istft(D_percussive), sr=sr)), ref=np.max) p=librosa.display.specshow(CQT,x_axis=None,y_axis=None) plt.axis(&#39;off&#39;) . (0.0, 87.0, 0.0, 84.0) . Save the file . p.figure.savefig(&#39;test.png&#39;) . and try opening and displaying it. . from IPython.display import Image Image(filename=&#39;test.png&#39;) . Creating the training dataset . Load each sound file extracted from the videos and generate a spectrogram image of every two seconds of audio. . The soundfile package is used to save out each 2 second slice so that it can be listened to when evaluating the performance of the classifier after training. . !pip install soundfile . Collecting soundfile Downloading https://files.pythonhosted.org/packages/68/64/1191352221e2ec90db7492b4bf0c04fd9d2508de67b3f39cbf093cd6bd86/SoundFile-0.10.2-py2.py3-none-any.whl Requirement already satisfied: cffi&gt;=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.12.3) Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi&gt;=1.0-&gt;soundfile) (2.19) Installing collected packages: soundfile Successfully installed soundfile-0.10.2 . First a class to represent the spectrogram. The idea was to give it functions for each step in the process detailed above and call them in a loop. But this was determined to be the concern of a future refactoring. Now the class is a bit redundant, a function would have sufficed. . class Spectrogram: def __init__(self, audiofile_path, dpi=150, side_px=256, total_duration=10, duration=2): import numpy as np import matplotlib.pyplot as plt import librosa import librosa.display import os import soundfile as sf filepath, extension = os.path.splitext(audiofile_path) slices = int(total_duration / duration) for i in range(slices): spectrogram_path = filepath + &#39;_&#39; + str(i) + &#39;.png&#39; audio_slice_path = filepath + &#39;_&#39; + str(i) + &#39;.wav&#39; y, sr = librosa.load(audiofile_path, duration=duration, offset=duration*i) sf.write(audio_slice_path,y,sr) D = librosa.stft(y) D_harmonic, D_percussive = librosa.decompose.hpss(D) # Pre-compute a global reference power from the input spectrum rp = np.max(np.abs(D)) plt.figure(figsize=(side_px/dpi, side_px/dpi)) CQT = librosa.amplitude_to_db(np.abs(librosa.cqt(librosa.istft(D_percussive), sr=sr)), ref=np.max) p=librosa.display.specshow(CQT,x_axis=None,y_axis=None) plt.axis(&#39;off&#39;) figure = p.figure figure.savefig(spectrogram_path) plt.close(figure) . The actual batch job is run by these nested for loops. . import os dirs = [base_dir+&#39;knocking/&#39;,base_dir+&#39;normal/&#39;] for dirry in dirs: print(dirry) for filename in os.listdir(dirry): if filename.endswith(&#39;.wav&#39;): print(filename) Spectrogram(dirry+filename) . /content/gdrive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/knocking/ 0005.wav 0004.wav 0010.wav 0003.wav 0011.wav 0002.wav 0009.wav 0006.wav 0007.wav 0008.wav 0013.wav 0014.wav 0012.wav 0020.wav 0021.wav 0016.wav 0015.wav 0017.wav 0018.wav 0019.wav 0022.wav 0029.wav 0030.wav 0027.wav 0031.wav 0028.wav 0026.wav 0023.wav 0024.wav 0025.wav 0037.wav 0033.wav 0035.wav 0040.wav 0034.wav 0036.wav 0042.wav 0032.wav 0039.wav 0041.wav 0044.wav 0045.wav 0001.wav 0043.wav 0046.wav /content/gdrive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/normal/ 0004.wav 0012.wav 0011.wav 0010.wav 0007.wav 0009.wav 0013.wav 0008.wav 0006.wav 0005.wav 0023.wav 0021.wav 0019.wav 0022.wav 0014.wav 0020.wav 0017.wav 0016.wav 0018.wav 0015.wav 0029.wav 0027.wav 0026.wav 0032.wav 0030.wav 0028.wav 0024.wav 0031.wav 0033.wav 0025.wav 0034.wav 0043.wav 0036.wav 0042.wav 0039.wav 0041.wav 0037.wav 0035.wav 0038.wav 0040.wav 0003.wav 0046.wav 0002.wav 0001.wav 0044.wav 0045.wav 0047.wav . .",
            "url": "https://niklasekman.com/2019/09/14/Create_spectrogram_commented.html",
            "relUrl": "/2019/09/14/Create_spectrogram_commented.html",
            "date": " • Sep 14, 2019"
        }
        
    
  
    
        ,"post4": {
            "title": "Engine knock detection AI part 1/5",
            "content": "Background . The inspiration for this project comes from the presentation of fast.ai course alumni projects by Jeremy Howard in some of the first lessons of the third installment of Practical Deep Learning for Coders where training an image classifier using spectrograms to identify sounds is mentioned. . What this means in simpler terms is that an image classifying algorithm is presented with a series of pictures labeled with which class or case they represent. Each picture represents what that sound looks like if one were to plot the sound intensities at different frequencies as a function of time. . Method . A set of recordings of both knocking and healthy sounding engines has first to be aquired in order to create a training set of spectrograms. I&#39;ve chosen to create two playlists on youtube of videos specifically depicting car engines, one for each case. I made sure to just include petrol engines since my suspicion was that the sound of a diesel engine might throw things off. . As a non car mechanic I made that assumption based on the idea that if I could distinguish a well running engine from a knocking one then the resulting model could do it too. I found that I had some trouble making the distinction with some of the cold started diesels I listened to. . Downloading audio files . After creating the playlists Google Drive is mounted to store the intermediary sound files. . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&amp;response_type=code Enter your authorization code: ·········· Mounted at /content/drive . . The youtube-dl python package is installed and the soundtrack from each of the videos is downloaded. . !pip install --upgrade youtube-dl . Collecting youtube-dl Downloading https://files.pythonhosted.org/packages/42/9c/9e13d8c2cb43dc158ede19e5dade9037fa5ee321e70494a3960d62f9242b/youtube_dl-2019.9.12.1-py2.py3-none-any.whl (1.8MB) |████████████████████████████████| 1.8MB 2.8MB/s Installing collected packages: youtube-dl Successfully installed youtube-dl-2019.9.12.1 . import youtube_dl . ydl = youtube_dl.YoutubeDL({&#39;outtmpl&#39;: &#39;%(id)s%(ext)s&#39;}) ydl_opts = { &#39;format&#39;: &#39;bestaudio/best&#39;, &#39;postprocessors&#39;: [{ &#39;key&#39;: &#39;FFmpegExtractAudio&#39;, &#39;preferredcodec&#39;: &#39;mp3&#39;, &#39;preferredquality&#39;: &#39;192&#39;, }], } with youtube_dl.YoutubeDL(ydl_opts) as ydl: ydl.download([&#39;https://www.youtube.com/playlist?list=PL9R1Zswn-XPCh3A3bV9Vnf7ui9YCZWo9w&#39;]) . [youtube:playlist] PL9R1Zswn-XPCh3A3bV9Vnf7ui9YCZWo9w: Downloading webpage [download] Downloading playlist: engine_normal [youtube:playlist] playlist engine_normal: Downloading 15 videos [download] Downloading video 1 of 15 [youtube] ho38ZYkQJxs: Downloading webpage [youtube] ho38ZYkQJxs: Downloading video info webpage [download] Destination: 2003 toyota corolla engine sound-ho38ZYkQJxs.webm [download] 100% of 2.44MiB in 00:00 [ffmpeg] Destination: 2003 toyota corolla engine sound-ho38ZYkQJxs.mp3 Deleting original file 2003 toyota corolla engine sound-ho38ZYkQJxs.webm (pass -k to keep) [download] Downloading video 2 of 15 [youtube] Eky3PMh76gY: Downloading webpage [youtube] Eky3PMh76gY: Downloading video info webpage [youtube] Eky3PMh76gY: Downloading MPD manifest [dashsegments] Total fragments: 8 [download] Destination: 2017 Hyundai Elantra SE 2.0L 4 Cylinder - Normal Engine Running Noises-Eky3PMh76gY.webm [download] 100% of 1.04MiB in 00:02 [ffmpeg] Destination: 2017 Hyundai Elantra SE 2.0L 4 Cylinder - Normal Engine Running Noises-Eky3PMh76gY.mp3 Deleting original file 2017 Hyundai Elantra SE 2.0L 4 Cylinder - Normal Engine Running Noises-Eky3PMh76gY.webm (pass -k to keep) [download] Downloading video 3 of 15 [youtube] YiwsC_UlDFY: Downloading webpage [youtube] YiwsC_UlDFY: Downloading video info webpage [youtube] YiwsC_UlDFY: Downloading MPD manifest [dashsegments] Total fragments: 3 [download] Destination: Nissan Frontier 4L v6 engine sound idle-YiwsC_UlDFY.webm [download] 100% of 195.58KiB in 00:01 [ffmpeg] Destination: Nissan Frontier 4L v6 engine sound idle-YiwsC_UlDFY.mp3 Deleting original file Nissan Frontier 4L v6 engine sound idle-YiwsC_UlDFY.webm (pass -k to keep) [download] Downloading video 4 of 15 [youtube] uumxLAHbDsE: Downloading webpage [youtube] uumxLAHbDsE: Downloading video info webpage [download] Destination: Volvo S60 2.0T - Normal engine sound-uumxLAHbDsE.webm [download] 100% of 428.44KiB in 00:00 [ffmpeg] Destination: Volvo S60 2.0T - Normal engine sound-uumxLAHbDsE.mp3 Deleting original file Volvo S60 2.0T - Normal engine sound-uumxLAHbDsE.webm (pass -k to keep) [download] Downloading video 5 of 15 [youtube] 8cXmy_U0_28: Downloading webpage [youtube] 8cXmy_U0_28: Downloading video info webpage [download] Destination: Mini R56S normal engine sound-8cXmy_U0_28.webm [download] 100% of 526.86KiB in 00:00 [ffmpeg] Destination: Mini R56S normal engine sound-8cXmy_U0_28.mp3 Deleting original file Mini R56S normal engine sound-8cXmy_U0_28.webm (pass -k to keep) [download] Downloading video 6 of 15 [youtube] nGQcC7giMkU: Downloading webpage [youtube] nGQcC7giMkU: Downloading video info webpage [download] Destination: 2016 Kia Rio 1.6L V4 Engine - Normal Running Noises _ Sounds-nGQcC7giMkU.m4a [download] 100% of 1.05MiB in 00:00 [ffmpeg] Correcting container in &#34;2016 Kia Rio 1.6L V4 Engine - Normal Running Noises _ Sounds-nGQcC7giMkU.m4a&#34; [ffmpeg] Destination: 2016 Kia Rio 1.6L V4 Engine - Normal Running Noises _ Sounds-nGQcC7giMkU.mp3 Deleting original file 2016 Kia Rio 1.6L V4 Engine - Normal Running Noises _ Sounds-nGQcC7giMkU.m4a (pass -k to keep) [download] Downloading video 7 of 15 [youtube] 2EQcfJAU7IM: Downloading webpage [youtube] 2EQcfJAU7IM: Downloading video info webpage [youtube] 2EQcfJAU7IM: Downloading MPD manifest [dashsegments] Total fragments: 8 [download] Destination: 2017 Kia Rio 1.6L 4 Cylinder GDI Engine - Normal Engine Sounds-2EQcfJAU7IM.webm [download] 100% of 1.02MiB in 00:02 [ffmpeg] Destination: 2017 Kia Rio 1.6L 4 Cylinder GDI Engine - Normal Engine Sounds-2EQcfJAU7IM.mp3 Deleting original file 2017 Kia Rio 1.6L 4 Cylinder GDI Engine - Normal Engine Sounds-2EQcfJAU7IM.webm (pass -k to keep) [download] Downloading video 8 of 15 [youtube] PRO0HgD9qx4: Downloading webpage [youtube] PRO0HgD9qx4: Downloading video info webpage [youtube] PRO0HgD9qx4: Downloading MPD manifest [dashsegments] Total fragments: 14 [download] Destination: 2017 Nissan Versa Note - Normal Engine Running Noises - 1.6L Engine-PRO0HgD9qx4.m4a [download] 100% of 949.79KiB in 00:01 [ffmpeg] Correcting container in &#34;2017 Nissan Versa Note - Normal Engine Running Noises - 1.6L Engine-PRO0HgD9qx4.m4a&#34; [ffmpeg] Destination: 2017 Nissan Versa Note - Normal Engine Running Noises - 1.6L Engine-PRO0HgD9qx4.mp3 Deleting original file 2017 Nissan Versa Note - Normal Engine Running Noises - 1.6L Engine-PRO0HgD9qx4.m4a (pass -k to keep) [download] Downloading video 9 of 15 [youtube] 6GPgodkLSkQ: Downloading webpage [youtube] 6GPgodkLSkQ: Downloading video info webpage [download] Destination: Listen Toyota 2.4 VVT-i engine sound, when engine is very OK. Years 2002 to 2015-6GPgodkLSkQ.webm [download] 100% of 1.93MiB in 00:00 [ffmpeg] Destination: Listen Toyota 2.4 VVT-i engine sound, when engine is very OK. Years 2002 to 2015-6GPgodkLSkQ.mp3 Deleting original file Listen Toyota 2.4 VVT-i engine sound, when engine is very OK. Years 2002 to 2015-6GPgodkLSkQ.webm (pass -k to keep) [download] Downloading video 10 of 15 [youtube] pLmX2ws7znE: Downloading webpage [youtube] pLmX2ws7znE: Downloading video info webpage [youtube] pLmX2ws7znE: Downloading MPD manifest [dashsegments] Total fragments: 4 [download] Destination: 2018 Hyundai Tucson 2.0 GDI Nu Engine Sound Normal-pLmX2ws7znE.m4a [download] 100% of 451.64KiB in 00:00 [ffmpeg] Correcting container in &#34;2018 Hyundai Tucson 2.0 GDI Nu Engine Sound Normal-pLmX2ws7znE.m4a&#34; [ffmpeg] Destination: 2018 Hyundai Tucson 2.0 GDI Nu Engine Sound Normal-pLmX2ws7znE.mp3 Deleting original file 2018 Hyundai Tucson 2.0 GDI Nu Engine Sound Normal-pLmX2ws7znE.m4a (pass -k to keep) [download] Downloading video 11 of 15 [youtube] mOFcfwLTNkY: Downloading webpage [youtube] mOFcfwLTNkY: Downloading video info webpage [download] Destination: 3.2 fsi engine sound cold (normal or not)-mOFcfwLTNkY.m4a [download] 100% of 928.43KiB in 00:00 [ffmpeg] Correcting container in &#34;3.2 fsi engine sound cold (normal or not)-mOFcfwLTNkY.m4a&#34; [ffmpeg] Destination: 3.2 fsi engine sound cold (normal or not)-mOFcfwLTNkY.mp3 Deleting original file 3.2 fsi engine sound cold (normal or not)-mOFcfwLTNkY.m4a (pass -k to keep) [download] Downloading video 12 of 15 [youtube] 5q1uATQu8zg: Downloading webpage [youtube] 5q1uATQu8zg: Downloading video info webpage [youtube] 5q1uATQu8zg: Downloading MPD manifest [dashsegments] Total fragments: 13 [download] Destination: Normal Engine Idle Sound Cold &amp; Warm - 2006 Nissan Sentra-5q1uATQu8zg.webm [download] 100% of 1.86MiB in 00:07 [ffmpeg] Destination: Normal Engine Idle Sound Cold &amp; Warm - 2006 Nissan Sentra-5q1uATQu8zg.mp3 Deleting original file Normal Engine Idle Sound Cold &amp; Warm - 2006 Nissan Sentra-5q1uATQu8zg.webm (pass -k to keep) [download] Downloading video 13 of 15 [youtube] 8BOtWY3RobA: Downloading webpage [youtube] 8BOtWY3RobA: Downloading video info webpage [download] Destination: 1996 Subaru Outback, Normal Engine Sound-8BOtWY3RobA.webm [download] 100% of 956.87KiB in 00:00 [ffmpeg] Destination: 1996 Subaru Outback, Normal Engine Sound-8BOtWY3RobA.mp3 Deleting original file 1996 Subaru Outback, Normal Engine Sound-8BOtWY3RobA.webm (pass -k to keep) [download] Downloading video 14 of 15 [youtube] bkPtY1pW82Y: Downloading webpage [youtube] bkPtY1pW82Y: Downloading video info webpage [youtube] bkPtY1pW82Y: Downloading MPD manifest [dashsegments] Total fragments: 15 [download] Destination: Bmw f30 Noisy Engine Sound-bkPtY1pW82Y.m4a [download] 100% of 1.01MiB in 00:01 [ffmpeg] Correcting container in &#34;Bmw f30 Noisy Engine Sound-bkPtY1pW82Y.m4a&#34; [ffmpeg] Destination: Bmw f30 Noisy Engine Sound-bkPtY1pW82Y.mp3 Deleting original file Bmw f30 Noisy Engine Sound-bkPtY1pW82Y.m4a (pass -k to keep) [download] Downloading video 15 of 15 [youtube] nSB65kClSXM: Downloading webpage [youtube] nSB65kClSXM: Downloading video info webpage [youtube] nSB65kClSXM: Downloading MPD manifest [dashsegments] Total fragments: 4 [download] Destination: 2016-2018 Toyota Tacoma Loud Engine sound is Normal-nSB65kClSXM.webm [download] 100% of 382.73KiB in 00:01 [ffmpeg] Destination: 2016-2018 Toyota Tacoma Loud Engine sound is Normal-nSB65kClSXM.mp3 Deleting original file 2016-2018 Toyota Tacoma Loud Engine sound is Normal-nSB65kClSXM.webm (pass -k to keep) [download] Finished downloading playlist: engine_normal . . !rm -rf ./sample_data . Checking to see that all the expected files are present. . !ls *.mp3 . &#39;1996 Subaru Outback, Normal Engine Sound-8BOtWY3RobA.mp3&#39; &#39;2003 toyota corolla engine sound-ho38ZYkQJxs.mp3&#39; &#39;2016-2018 Toyota Tacoma Loud Engine sound is Normal-nSB65kClSXM.mp3&#39; &#39;2016 Kia Rio 1.6L V4 Engine - Normal Running Noises _ Sounds-nGQcC7giMkU.mp3&#39; &#39;2017 Hyundai Elantra SE 2.0L 4 Cylinder - Normal Engine Running Noises-Eky3PMh76gY.mp3&#39; &#39;2017 Kia Rio 1.6L 4 Cylinder GDI Engine - Normal Engine Sounds-2EQcfJAU7IM.mp3&#39; &#39;2017 Nissan Versa Note - Normal Engine Running Noises - 1.6L Engine-PRO0HgD9qx4.mp3&#39; &#39;2018 Hyundai Tucson 2.0 GDI Nu Engine Sound Normal-pLmX2ws7znE.mp3&#39; &#39;3.2 fsi engine sound cold (normal or not)-mOFcfwLTNkY.mp3&#39; &#39;Bmw f30 Noisy Engine Sound-bkPtY1pW82Y.mp3&#39; &#39;Listen Toyota 2.4 VVT-i engine sound, when engine is very OK. Years 2002 to 2015-6GPgodkLSkQ.mp3&#39; &#39;Mini R56S normal engine sound-8cXmy_U0_28.mp3&#39; &#39;Nissan Frontier 4L v6 engine sound idle-YiwsC_UlDFY.mp3&#39; &#39;Normal Engine Idle Sound Cold &amp; Warm - 2006 Nissan Sentra-5q1uATQu8zg.mp3&#39; &#39;Volvo S60 2.0T - Normal engine sound-uumxLAHbDsE.mp3&#39; . Moving the sound files from the Colab instance to a folder on Google Drive. . !mv *.mp3 /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/normal/ . Rinse and repeat for the other playlist. . ydl_opts = { &#39;format&#39;: &#39;bestaudio/best&#39;, &#39;postprocessors&#39;: [{ &#39;key&#39;: &#39;FFmpegExtractAudio&#39;, &#39;preferredcodec&#39;: &#39;mp3&#39;, &#39;preferredquality&#39;: &#39;192&#39;, }], } with youtube_dl.YoutubeDL(ydl_opts) as ydl: ydl.download([&#39;https://www.youtube.com/playlist?list=PL9R1Zswn-XPCnpyXQLRPYVJr4BXJUYie8&#39;]) . [youtube:playlist] PL9R1Zswn-XPCnpyXQLRPYVJr4BXJUYie8: Downloading webpage [download] Downloading playlist: engine_knocking [youtube:playlist] playlist engine_knocking: Downloading 15 videos [download] Downloading video 1 of 15 [youtube] JIOdS7XbHys: Downloading webpage [youtube] JIOdS7XbHys: Downloading video info webpage [download] Destination: How To Diagnose An Engine Knock.MP4-JIOdS7XbHys.webm [download] 100% of 3.87MiB in 00:00 [ffmpeg] Destination: How To Diagnose An Engine Knock.MP4-JIOdS7XbHys.mp3 Deleting original file How To Diagnose An Engine Knock.MP4-JIOdS7XbHys.webm (pass -k to keep) [download] Downloading video 2 of 15 [youtube] gBA1zC5duuI: Downloading webpage [youtube] gBA1zC5duuI: Downloading video info webpage [download] Destination: Engine Noise Diagnosis-Part 1-gBA1zC5duuI.webm [download] 100% of 17.50MiB in 00:00 [ffmpeg] Destination: Engine Noise Diagnosis-Part 1-gBA1zC5duuI.mp3 Deleting original file Engine Noise Diagnosis-Part 1-gBA1zC5duuI.webm (pass -k to keep) [download] Downloading video 3 of 15 [youtube] TjtNcBD4Uwk: Downloading webpage [youtube] TjtNcBD4Uwk: Downloading video info webpage [download] Destination: Engine Noise Diagnosis Part 2- The Answer Revealed!-TjtNcBD4Uwk.webm [download] 100% of 8.50MiB in 00:00 [ffmpeg] Destination: Engine Noise Diagnosis Part 2- The Answer Revealed!-TjtNcBD4Uwk.mp3 Deleting original file Engine Noise Diagnosis Part 2- The Answer Revealed!-TjtNcBD4Uwk.webm (pass -k to keep) [download] Downloading video 4 of 15 [youtube] wf8e_Ivi72Q: Downloading webpage [youtube] wf8e_Ivi72Q: Downloading video info webpage [download] Destination: Engine Knock Diagnosis-wf8e_Ivi72Q.webm [download] 100% of 2.43MiB in 00:00 [ffmpeg] Destination: Engine Knock Diagnosis-wf8e_Ivi72Q.mp3 Deleting original file Engine Knock Diagnosis-wf8e_Ivi72Q.webm (pass -k to keep) [download] Downloading video 5 of 15 [youtube] kBWXxWD7g30: Downloading webpage [youtube] kBWXxWD7g30: Downloading video info webpage [download] Destination: Engine knocking sounds-kBWXxWD7g30.webm [download] 100% of 571.70KiB in 00:00 [ffmpeg] Destination: Engine knocking sounds-kBWXxWD7g30.mp3 Deleting original file Engine knocking sounds-kBWXxWD7g30.webm (pass -k to keep) [download] Downloading video 6 of 15 [youtube] IRcZo89RJzI: Downloading webpage [youtube] IRcZo89RJzI: Downloading video info webpage [youtube] IRcZo89RJzI: Downloading MPD manifest [dashsegments] Total fragments: 39 [download] Destination: Ticking or Knocking Engine-IRcZo89RJzI.m4a [download] 100% of 2.83MiB in 00:03 [ffmpeg] Correcting container in &#34;Ticking or Knocking Engine-IRcZo89RJzI.m4a&#34; [ffmpeg] Destination: Ticking or Knocking Engine-IRcZo89RJzI.mp3 Deleting original file Ticking or Knocking Engine-IRcZo89RJzI.m4a (pass -k to keep) [download] Downloading video 7 of 15 [youtube] Zh8e9MGam8Q: Downloading webpage [youtube] Zh8e9MGam8Q: Downloading video info webpage [download] Destination: Engine Knocking-Zh8e9MGam8Q.m4a [download] 100% of 1.01MiB in 00:00 [ffmpeg] Correcting container in &#34;Engine Knocking-Zh8e9MGam8Q.m4a&#34; [ffmpeg] Destination: Engine Knocking-Zh8e9MGam8Q.mp3 Deleting original file Engine Knocking-Zh8e9MGam8Q.m4a (pass -k to keep) [download] Downloading video 8 of 15 [youtube] lGC51mIQylk: Downloading webpage [youtube] lGC51mIQylk: Downloading video info webpage [download] Destination: What Does Detonation _ Spark Knock Sound Like-lGC51mIQylk.m4a [download] 100% of 2.04MiB in 00:00 [ffmpeg] Correcting container in &#34;What Does Detonation _ Spark Knock Sound Like-lGC51mIQylk.m4a&#34; [ffmpeg] Destination: What Does Detonation _ Spark Knock Sound Like-lGC51mIQylk.mp3 Deleting original file What Does Detonation _ Spark Knock Sound Like-lGC51mIQylk.m4a (pass -k to keep) [download] Downloading video 9 of 15 [youtube] rk_iOIumShQ: Downloading webpage [youtube] rk_iOIumShQ: Downloading video info webpage [download] Destination: Engine knocking sound-rk_iOIumShQ.m4a [download] 100% of 763.43KiB in 00:00 [ffmpeg] Correcting container in &#34;Engine knocking sound-rk_iOIumShQ.m4a&#34; [ffmpeg] Destination: Engine knocking sound-rk_iOIumShQ.mp3 Deleting original file Engine knocking sound-rk_iOIumShQ.m4a (pass -k to keep) [download] Downloading video 10 of 15 [youtube] n0jys2TEXDk: Downloading webpage [youtube] n0jys2TEXDk: Downloading video info webpage [download] Destination: Ford Vehicle Noises - #4 Tapping Knocking Noise 2.5L Engines-n0jys2TEXDk.webm [download] 100% of 3.72MiB in 00:00 [ffmpeg] Destination: Ford Vehicle Noises - #4 Tapping Knocking Noise 2.5L Engines-n0jys2TEXDk.mp3 Deleting original file Ford Vehicle Noises - #4 Tapping Knocking Noise 2.5L Engines-n0jys2TEXDk.webm (pass -k to keep) [download] Downloading video 11 of 15 [youtube] e79c_-_hVa8: Downloading webpage [youtube] e79c_-_hVa8: Downloading video info webpage [youtube] e79c_-_hVa8: Downloading MPD manifest [dashsegments] Total fragments: 7 [download] Destination: Spun _ Knocking Rod Bearing Noise-e79c_-_hVa8.webm [download] 100% of 1.02MiB in 00:00 [ffmpeg] Destination: Spun _ Knocking Rod Bearing Noise-e79c_-_hVa8.mp3 Deleting original file Spun _ Knocking Rod Bearing Noise-e79c_-_hVa8.webm (pass -k to keep) [download] Downloading video 12 of 15 [youtube] rFuLwzb_VmE: Downloading webpage [youtube] rFuLwzb_VmE: Downloading video info webpage [download] Destination: Spark Knock or engine ping-rFuLwzb_VmE.m4a [download] 100% of 365.87KiB in 00:00 [ffmpeg] Correcting container in &#34;Spark Knock or engine ping-rFuLwzb_VmE.m4a&#34; [ffmpeg] Destination: Spark Knock or engine ping-rFuLwzb_VmE.mp3 Deleting original file Spark Knock or engine ping-rFuLwzb_VmE.m4a (pass -k to keep) [download] Downloading video 13 of 15 [youtube] wmtBqNnnvrs: Downloading webpage [youtube] wmtBqNnnvrs: Downloading video info webpage [youtube] wmtBqNnnvrs: Downloading MPD manifest [dashsegments] Total fragments: 20 [download] Destination: Ever Wonder What Rod Knock Sounds Like-wmtBqNnnvrs.webm [download] 100% of 3.18MiB in 00:05 [ffmpeg] Destination: Ever Wonder What Rod Knock Sounds Like-wmtBqNnnvrs.mp3 Deleting original file Ever Wonder What Rod Knock Sounds Like-wmtBqNnnvrs.webm (pass -k to keep) [download] Downloading video 14 of 15 [youtube] 8EZEwMqJj1U: Downloading webpage [youtube] 8EZEwMqJj1U: Downloading video info webpage [download] Destination: Engine knocking_Pinging sound at idle...-8EZEwMqJj1U.webm [download] 100% of 1.35MiB in 00:00 [ffmpeg] Destination: Engine knocking_Pinging sound at idle...-8EZEwMqJj1U.mp3 Deleting original file Engine knocking_Pinging sound at idle...-8EZEwMqJj1U.webm (pass -k to keep) [download] Downloading video 15 of 15 [youtube] uRtyPbyomxQ: Downloading webpage [youtube] uRtyPbyomxQ: Downloading video info webpage [download] Destination: HYUNDAI ELANTRA ENGINE KNOCK TICKING NOISE-uRtyPbyomxQ.webm [download] 100% of 5.25MiB in 00:00 [ffmpeg] Destination: HYUNDAI ELANTRA ENGINE KNOCK TICKING NOISE-uRtyPbyomxQ.mp3 Deleting original file HYUNDAI ELANTRA ENGINE KNOCK TICKING NOISE-uRtyPbyomxQ.webm (pass -k to keep) [download] Finished downloading playlist: engine_knocking . . !mv *.mp3 /content/drive/My Drive/Colab Notebooks/fast.ai/KnockKnock/data/knocking/ . Slicing audio files . The 15 mp3 files were then sliced into 10 second clips in Audacity. This could probably have been done programmatically but as trivial as the task initally may sound there would most likely have been complications. The videos do not only show the car running with the hood popped up. There&#39;s some talking, explaining and fumbling around in quite a few of them. .",
            "url": "https://niklasekman.com/2019/09/13/youtube-dl_commented.html",
            "relUrl": "/2019/09/13/youtube-dl_commented.html",
            "date": " • Sep 13, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a Marine electrician with a software design background currently studying for a Bachelor of Engineering in Electrical Engineering. . When I’m not sweating in a hot engine room, lying on deck plates, while reaching for a bilge level switch amid 100°C fuel oil pipes like I’m about to in the picture above, hence the expression, I like to make and experiment. I benefit of having multiclassed in both CS and EE in addition to photography among other things. While my knowledge isn’t as deep in any particular subject, I’m backed up by the breadth of things I’m familiar with. .",
          "url": "https://niklasekman.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://niklasekman.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}